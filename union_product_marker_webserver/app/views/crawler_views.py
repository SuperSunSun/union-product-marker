"""
çˆ¬è™«æ•°æ®ç®¡ç†è§†å›¾æ¨¡å—

è¿™ä¸ªæ¨¡å—å¤„ç†çˆ¬è™«æ•°æ®çš„ä¸Šä¼ ã€ç®¡ç†å’Œç»Ÿè®¡åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
1. çˆ¬è™«æ•°æ®æ–‡ä»¶ä¸Šä¼ å’Œé¢„è§ˆ
2. æ•°æ®å¯¼å…¥åˆ°æ•°æ®åº“
3. æ•°æ®ç»Ÿè®¡å’Œæ¦‚è§ˆ
4. æ•°æ®æºç®¡ç†

ä¸»è¦åŠŸèƒ½ï¼š
- æ”¯æŒJSONæ ¼å¼çš„çˆ¬è™«æ•°æ®ä¸Šä¼ 
- æ•°æ®é¢„è§ˆå’ŒéªŒè¯
- æ‰¹é‡å¯¼å…¥çˆ¬è™«æ•°æ®
- æ•°æ®ç»Ÿè®¡å’Œæ¥æºåˆ†æ
- æ•°æ®æºåˆ é™¤å’Œç®¡ç†

ä½œè€…: Union Product Marker Team
ç‰ˆæœ¬: 1.0.0
"""

import json
import os
from datetime import datetime
from flask import Blueprint, render_template, request, jsonify, current_app
from app.utils.db_util import get_db_connection

# çˆ¬è™«æ•°æ®ä¸Šä¼ è“å›¾
crawler_upload_bp = Blueprint("crawler_upload", __name__)

@crawler_upload_bp.route("/crawler-upload")
def crawler_upload():
    """
    çˆ¬è™«æ•°æ®ä¸Šä¼ é¡µé¢
    
    æ˜¾ç¤ºçˆ¬è™«æ•°æ®ä¸Šä¼ çš„ç•Œé¢ï¼Œç”¨æˆ·å¯ä»¥ï¼š
    - ä¸Šä¼ JSONæ ¼å¼çš„çˆ¬è™«æ•°æ®æ–‡ä»¶
    - é¢„è§ˆæ•°æ®å†…å®¹
    - æ‰§è¡Œæ•°æ®å¯¼å…¥
    
    Returns:
        str: æ¸²æŸ“åçš„ä¸Šä¼ é¡µé¢HTML
    """
    return render_template("crawler_upload.html")

@crawler_upload_bp.route("/crawler-upload/preview", methods=["POST"])
def preview_crawler_data():
    """
    é¢„è§ˆçˆ¬è™«æ•°æ®
    
    æ¥æ”¶ä¸Šä¼ çš„JSONæ–‡ä»¶ï¼Œè§£æå¹¶è¿”å›æ•°æ®ç»Ÿè®¡ä¿¡æ¯ï¼Œ
    ä¾›ç”¨æˆ·ç¡®è®¤åæ‰§è¡Œå¯¼å…¥ã€‚
    
    Returns:
        JSON: åŒ…å«æ•°æ®ç»Ÿè®¡å’Œé¢„è§ˆä¿¡æ¯
            {
                "success": true,
                "stats": {
                    "total_sources": æ•°æ®æºæ€»æ•°,
                    "total_products": äº§å“æ€»æ•°,
                    "sources": [{"name": "æ¥æºå", "count": äº§å“æ•°é‡}]
                },
                "data": åŸå§‹æ•°æ®,
                "filename": æ–‡ä»¶å
            }
    """
    try:
        # è·å–ä¸Šä¼ çš„æ–‡ä»¶
        file = request.files.get("file")
        if not file:
            return jsonify({"error": "æœªä¸Šä¼ æ–‡ä»¶"}), 400

        # è¯»å–JSONæ–‡ä»¶å†…å®¹
        content = file.read().decode("utf-8")
        data = json.loads(content)
        
        # éªŒè¯æ•°æ®ç»“æ„
        if not isinstance(data, dict) or "products" not in data:
            return jsonify({"error": "æ— æ•ˆçš„JSONç»“æ„ï¼šç¼ºå°‘productså­—æ®µ"}), 400
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "total_sources": len(data.get("products", {})),
            "total_products": 0,
            "sources": []
        }
        
        # è®¡ç®—æ¯ä¸ªæ¥æºçš„äº§å“æ•°é‡
        for source_name, products in data.get("products", {}).items():
            if isinstance(products, list):
                stats["total_products"] += len(products)
                stats["sources"].append({
                    "name": source_name,
                    "count": len(products)
                })
        
        # è¿”å›é¢„è§ˆæ•°æ®
        return jsonify({
            "success": True,
            "stats": stats,
            "data": data,
            "filename": file.filename
        })
        
    except json.JSONDecodeError as e:
        return jsonify({"error": f"JSONè§£æé”™è¯¯: {str(e)}"}), 400
    except Exception as e:
        return jsonify({"error": f"å¤„ç†å¤±è´¥: {str(e)}"}), 500

@crawler_upload_bp.route("/crawler-upload/import", methods=["POST"])
def import_crawler_data():
    """
    å¯¼å…¥çˆ¬è™«æ•°æ®åˆ°æ•°æ®åº“
    
    æ¥æ”¶å‰ç«¯å‘é€çš„çˆ¬è™«æ•°æ®ï¼Œå°†å…¶å¯¼å…¥åˆ°sourcesè¡¨ä¸­ã€‚
    æ”¯æŒæ–°å¢å’Œæ›´æ–°æ“ä½œï¼ŒåŒæ—¶ç¡®ä¿productsè¡¨ä¸­å­˜åœ¨å¯¹åº”çš„äº§å“è®°å½•ã€‚
    
    Returns:
        JSON: å¯¼å…¥ç»“æœä¿¡æ¯
            {
                "success": true,
                "message": "å¯¼å…¥å®Œæˆï¼šæ–°å¢ X æ¡ï¼Œæ›´æ–° Y æ¡ã€‚"
            }
    """
    try:
        # è·å–å‰ç«¯å‘é€çš„æ•°æ®
        data = request.get_json()
        if not data or "data" not in data:
            return jsonify({"error": "æ— æ•ˆçš„è¯·æ±‚æ•°æ®"}), 400
        
        crawler_data = data["data"]  # è¿™é‡Œç›´æ¥æ˜¯productså¯¹è±¡ï¼Œä¸æ˜¯åŒ…å«productså­—æ®µçš„å¯¹è±¡
        source_name = data.get("source_name", "unknown")
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” è°ƒè¯•ä¿¡æ¯:")
        print(f"  - æ¥æ”¶åˆ°çš„æ•°æ®ç±»å‹: {type(crawler_data)}")
        print(f"  - æ•°æ®é”®: {list(crawler_data.keys()) if isinstance(crawler_data, dict) else 'N/A'}")
        
        # è·å–æ•°æ®åº“è¿æ¥
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # ç»Ÿè®¡å¯¼å…¥ç»“æœ
        inserted = 0
        updated = 0
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # å¤„ç†æ¯ä¸ªæ¥æºçš„æ•°æ® - crawler_dataç›´æ¥æ˜¯productså¯¹è±¡
        for source_key, products in crawler_data.items():
            if not isinstance(products, list):
                print(f"  - è·³è¿‡éåˆ—è¡¨æ•°æ®: {source_key} (ç±»å‹: {type(products)})")
                continue
                
            print(f"  - å¤„ç†æ¥æº: {source_key}, å•†å“æ•°é‡: {len(products)}")
            
            # å¤„ç†æ¯ä¸ªäº§å“
            for product in products:
                product_id = str(product.get("id", ""))
                if not product_id:
                    print(f"    - è·³è¿‡æ— IDå•†å“: {product.get('product_name', 'N/A')}")
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥æ¥æºçš„æ•°æ®
                cursor.execute(
                    "SELECT id FROM sources WHERE product_id = ? AND source_name = ?",
                    (product_id, source_key)
                )
                exists = cursor.fetchone()
                
                if exists:
                    # æ›´æ–°ç°æœ‰æ•°æ®
                    cursor.execute(
                        "UPDATE sources SET raw_json = ?, uploaded_at = ? WHERE product_id = ? AND source_name = ?",
                        (json.dumps(product), now, product_id, source_key)
                    )
                    updated += 1
                else:
                    # æ’å…¥æ–°æ•°æ®
                    cursor.execute(
                        "INSERT INTO sources (product_id, source_name, raw_json, uploaded_at) VALUES (?, ?, ?, ?)",
                        (product_id, source_key, json.dumps(product), now)
                    )
                    inserted += 1
                
                # ç¡®ä¿productsè¡¨ä¸­å­˜åœ¨è¯¥å•†å“
                cursor.execute("SELECT id FROM products WHERE id = ?", (product_id,))
                if not cursor.fetchone():
                    cursor.execute(
                        "INSERT INTO products (id, name, created_at, updated_at) VALUES (?, ?, ?, ?)",
                        (product_id, product.get("product_name", "æœªå‘½å"), now, now)
                    )
        
        # æäº¤äº‹åŠ¡å¹¶å…³é—­è¿æ¥
        conn.commit()
        conn.close()
        
        print(f"  - å¯¼å…¥ç»“æœ: æ–°å¢ {inserted} æ¡ï¼Œæ›´æ–° {updated} æ¡")
        
        return jsonify({
            "success": True,
            "message": f"âœ… å¯¼å…¥å®Œæˆï¼šæ–°å¢ {inserted} æ¡ï¼Œæ›´æ–° {updated} æ¡ã€‚"
        })
        
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}")
        return jsonify({"error": f"å¯¼å…¥å¤±è´¥: {str(e)}"}), 500

# çˆ¬è™«æ•°æ®ç®¡ç†è“å›¾
crawler_manage_bp = Blueprint("crawler_manage", __name__)

@crawler_manage_bp.route("/crawler-manage")
def crawler_manage():
    """
    çˆ¬è™«æ•°æ®ç®¡ç†é¡µé¢
    
    æ˜¾ç¤ºçˆ¬è™«æ•°æ®ç®¡ç†çš„ç•Œé¢ï¼Œç”¨æˆ·å¯ä»¥ï¼š
    - æŸ¥çœ‹æ•°æ®ç»Ÿè®¡ä¿¡æ¯
    - æµè§ˆæ‰€æœ‰äº§å“æ•°æ®
    - ç®¡ç†æ•°æ®æº
    - åˆ é™¤ç‰¹å®šæ•°æ®æº
    
    Returns:
        str: æ¸²æŸ“åçš„ç®¡ç†é¡µé¢HTML
    """
    return render_template("crawler_manage.html")

@crawler_manage_bp.route("/crawler-manage/statistics")
def get_statistics():
    """
    è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯
    
    è®¡ç®—å¹¶è¿”å›æ•°æ®åº“ä¸­çš„æ•°æ®ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    - äº§å“æ€»æ•°
    - æœ‰æ•°æ®çš„äº§å“æ•°é‡
    - æ•°æ®æºç»Ÿè®¡
    - è¦†ç›–ç‡åˆ†æ
    
    Returns:
        JSON: åŒ…å«è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
            {
                "success": true,
                "stats": {
                    "total_products": äº§å“æ€»æ•°,
                    "products_with_data": æœ‰æ•°æ®çš„äº§å“æ•°,
                    "total_sources": æ•°æ®æºæ€»æ•°,
                    "data_ratio": æ•°æ®è¦†ç›–ç‡,
                    "sources": [{"source_name": "æ¥æºå", "source_data_count": æ•°æ®é‡, "products_with_this_source": äº§å“æ•°, "source_ratio": è¦†ç›–ç‡}]
                }
            }
    """
    try:
        conn = get_db_connection()
        
        # 1. å•†å“æ€»æ•°ï¼šåº“å†…æ‰€æœ‰æœ‰IDçš„æ•°é‡
        cursor = conn.execute("SELECT COUNT(*) as total_products FROM products")
        total_products = cursor.fetchone()[0]
        
        # 2. æœ‰æ•°æ®å•†å“ï¼šæœ‰è‡³å°‘1ä¸ªæ¥æºæ•°æ®çš„å•†å“æ•°é‡
        cursor.execute("SELECT COUNT(DISTINCT product_id) as products_with_data FROM sources")
        products_with_data = cursor.fetchone()[0]
        
        # 3. æ¥æºæ•°æ®æ€»é‡ï¼šæ‰€æœ‰æ¥æºçš„çˆ¬è™«æ•°æ®æ€»é‡
        cursor.execute("SELECT COUNT(*) as total_sources FROM sources")
        total_sources = cursor.fetchone()[0]
        
        # 4. æœ‰æ•°æ®æ¯”ç‡ï¼šæœ‰æ•°æ®å•†å“æ•°/å•†å“æ€»æ•°
        data_ratio = (products_with_data / total_products * 100) if total_products > 0 else 0
        
        # 5. æ¯ä¸ªæ¥æºçš„ç»Ÿè®¡ä¿¡æ¯
        cursor.execute("""
            SELECT 
                source_name,
                COUNT(*) as source_data_count,
                COUNT(DISTINCT product_id) as products_with_this_source
            FROM sources
            GROUP BY source_name
            ORDER BY source_data_count DESC
        """)
        source_stats = cursor.fetchall()
        
        # è®¡ç®—æ¯ä¸ªæ¥æºçš„æœ‰æ•°æ®æ¯”ç‡
        sources_with_ratio = []
        for source in source_stats:
            source_dict = dict(source)
            source_ratio = (source_dict['products_with_this_source'] / total_products * 100) if total_products > 0 else 0
            source_dict['source_ratio'] = round(source_ratio, 1)
            sources_with_ratio.append(source_dict)
        
        conn.close()
        
        return jsonify({
            "success": True,
            "stats": {
                "total_products": total_products,
                "products_with_data": products_with_data,
                "total_sources": total_sources,
                "data_ratio": round(data_ratio, 1),
                "sources": sources_with_ratio
            }
        })
    except Exception as e:
        return jsonify({"error": f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}"}), 500

@crawler_manage_bp.route("/crawler-manage/all-data")
def get_all_data():
    """
    è·å–æ‰€æœ‰å•†å“æ•°æ®ï¼Œæ ¼å¼ä¸crawler_uploadä¸Šä¼ çš„JSONä¸€è‡´
    
    ä»æ•°æ®åº“æ£€ç´¢æ‰€æœ‰çˆ¬è™«æ•°æ®ï¼ŒæŒ‰æ¥æºåˆ†ç»„ï¼Œè¿”å›ä¸ä¸Šä¼ æ ¼å¼ä¸€è‡´çš„æ•°æ®ç»“æ„ã€‚
    è¿™å¯ä»¥ç”¨äºæ•°æ®å¯¼å‡ºæˆ–å¤‡ä»½ã€‚
    
    Returns:
        JSON: åŒ…å«æ‰€æœ‰çˆ¬è™«æ•°æ®ï¼ŒæŒ‰æ¥æºåˆ†ç»„
            {
                "success": true,
                "products": {
                    "æ¥æºå1": [äº§å“æ•°æ®åˆ—è¡¨],
                    "æ¥æºå2": [äº§å“æ•°æ®åˆ—è¡¨]
                }
            }
    """
    try:
        conn = get_db_connection()
        cursor = conn.execute("""
            SELECT s.product_id, s.source_name, s.raw_json, s.uploaded_at
            FROM sources s
            ORDER BY s.product_id, s.source_name
        """)
        sources = cursor.fetchall()
        conn.close()
        
        # æŒ‰æ¥æºåˆ†ç»„æ•°æ®
        products_by_source = {}
        
        for source in sources:
            try:
                raw_data = json.loads(source["raw_json"])
                source_name = source["source_name"]
                
                if source_name not in products_by_source:
                    products_by_source[source_name] = []
                
                products_by_source[source_name].append(raw_data)
                
            except json.JSONDecodeError:
                print(f"JSONè§£æå¤±è´¥: product_id={source['product_id']}, source_name={source['source_name']}")
                continue
        
        return jsonify({
            "success": True,
            "products": products_by_source
        })
    except Exception as e:
        return jsonify({"error": f"è·å–æ•°æ®å¤±è´¥: {str(e)}"}), 500

@crawler_manage_bp.route("/crawler-manage/products")
def get_products():
    """
    è·å–æ‰€æœ‰æœ‰çˆ¬è™«æ•°æ®çš„å•†å“åˆ—è¡¨
    
    æŸ¥è¯¢æ‰€æœ‰æœ‰çˆ¬è™«æ•°æ®çš„äº§å“ï¼ŒåŒ…æ‹¬æ¯ä¸ªäº§å“çš„æ•°æ®æºæ•°é‡ã€‚
    
    Returns:
        JSON: åŒ…å«äº§å“åˆ—è¡¨å’Œç»Ÿè®¡ä¿¡æ¯
            {
                "success": true,
                "products": [
                    {
                        "id": "äº§å“ID",
                        "name": "äº§å“åç§°",
                        "status": "çŠ¶æ€",
                        "updated_at": "æ›´æ–°æ—¶é—´",
                        "source_count": æ•°æ®æºæ•°é‡
                    }
                ]
            }
    """
    try:
        conn = get_db_connection()
        cursor = conn.execute("""
            SELECT DISTINCT p.id, p.name, p.status, p.updated_at,
                   COUNT(s.id) as source_count
            FROM products p
            INNER JOIN sources s ON p.id = s.product_id
            GROUP BY p.id, p.name, p.status, p.updated_at
            ORDER BY CAST(p.id AS INTEGER)
        """)
        products = cursor.fetchall()
        conn.close()
        
        return jsonify({
            "success": True,
            "products": [dict(p) for p in products]
        })
    except Exception as e:
        return jsonify({"error": f"è·å–å•†å“åˆ—è¡¨å¤±è´¥: {str(e)}"}), 500

@crawler_manage_bp.route("/crawler-manage/product/<product_id>")
def get_product_sources(product_id):
    """
    è·å–æŒ‡å®šå•†å“çš„æ‰€æœ‰æ¥æºæ•°æ®
    
    æŸ¥è¯¢æŒ‡å®šäº§å“çš„æ‰€æœ‰çˆ¬è™«æ•°æ®æºï¼ŒåŒ…æ‹¬åŸå§‹JSONæ•°æ®ã€‚
    
    Args:
        product_id (str): äº§å“ID
        
    Returns:
        JSON: åŒ…å«äº§å“ä¿¡æ¯å’Œæ‰€æœ‰æ•°æ®æº
            {
                "success": true,
                "product": äº§å“åŸºæœ¬ä¿¡æ¯,
                "sources": [
                    {
                        "source_name": "æ¥æºå",
                        "data": åŸå§‹æ•°æ®,
                        "uploaded_at": "ä¸Šä¼ æ—¶é—´"
                    }
                ]
            }
    """
    try:
        conn = get_db_connection()
        cursor = conn.execute("""
            SELECT s.source_name, s.raw_json, s.uploaded_at
            FROM sources s
            WHERE s.product_id = ?
            ORDER BY s.uploaded_at DESC
        """, (product_id,))
        sources = cursor.fetchall()
        
        # è·å–å•†å“åŸºæœ¬ä¿¡æ¯
        cursor.execute("SELECT * FROM products WHERE id = ?", (product_id,))
        product = cursor.fetchone()
        conn.close()
        
        # è§£æJSONæ•°æ®
        parsed_sources = []
        for source in sources:
            try:
                raw_data = json.loads(source["raw_json"])
                parsed_sources.append({
                    "source_name": source["source_name"],
                    "data": raw_data,
                    "uploaded_at": source["uploaded_at"]
                })
            except json.JSONDecodeError:
                parsed_sources.append({
                    "source_name": source["source_name"],
                    "data": {"error": "JSONè§£æå¤±è´¥"},
                    "uploaded_at": source["uploaded_at"]
                })
        
        return jsonify({
            "success": True,
            "product": dict(product) if product else None,
            "sources": parsed_sources
        })
    except Exception as e:
        return jsonify({"error": f"è·å–å•†å“æ•°æ®å¤±è´¥: {str(e)}"}), 500

@crawler_manage_bp.route("/crawler-manage/delete-source", methods=["POST"])
def delete_source():
    """
    åˆ é™¤æŒ‡å®šæ¥æºçš„æ•°æ®
    
    åˆ é™¤æŒ‡å®šäº§å“çš„ç‰¹å®šæ•°æ®æºã€‚å¦‚æœåˆ é™¤åè¯¥äº§å“æ²¡æœ‰ä»»ä½•æ•°æ®æºï¼Œ
    å¯ä»¥é€‰æ‹©æ˜¯å¦åŒæ—¶åˆ é™¤äº§å“è®°å½•ã€‚
    
    Returns:
        JSON: åˆ é™¤æ“ä½œç»“æœ
            {
                "success": true,
                "message": "åˆ é™¤æˆåŠŸ",
                "remaining_sources": å‰©ä½™æ•°æ®æºæ•°é‡
            }
    """
    try:
        data = request.get_json()
        product_id = data.get("product_id")
        source_name = data.get("source_name")
        
        if not product_id or not source_name:
            return jsonify({"error": "ç¼ºå°‘å¿…è¦å‚æ•°"}), 400
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # åˆ é™¤æŒ‡å®šçš„æ•°æ®æº
        cursor.execute(
            "DELETE FROM sources WHERE product_id = ? AND source_name = ?",
            (product_id, source_name)
        )
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…¶ä»–æ¥æºæ•°æ®
        cursor.execute(
            "SELECT COUNT(*) FROM sources WHERE product_id = ?",
            (product_id,)
        )
        remaining_sources = cursor.fetchone()[0]
        
        conn.commit()
        conn.close()
        
        return jsonify({
            "success": True,
            "message": f"æˆåŠŸåˆ é™¤ {source_name} çš„æ•°æ®",
            "remaining_sources": remaining_sources
        })
        
    except Exception as e:
        return jsonify({"error": f"åˆ é™¤å¤±è´¥: {str(e)}"}), 500 